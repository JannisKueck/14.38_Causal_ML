{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replication of this [kaggle notebook](https://www.kaggle.com/janniskueck/pm3-notebook-inference-clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "from sklearn import preprocessing\n",
    "import patsy\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import hdmpy\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV, ElasticNetCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "import itertools\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "from itertools import compress\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018414,
     "end_time": "2021-02-13T17:30:13.212232",
     "exception": false,
     "start_time": "2021-02-13T17:30:13.193818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook contains an example for teaching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016442,
     "end_time": "2021-02-13T17:30:13.246048",
     "exception": false,
     "start_time": "2021-02-13T17:30:13.229606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A Case Study: The Effect of Gun Ownership on Gun-Homicide Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017996,
     "end_time": "2021-02-13T17:30:13.281738",
     "exception": false,
     "start_time": "2021-02-13T17:30:13.263742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We consider the problem of estimating the effect of gun\n",
    "ownership on the homicide rate. For this purpose, we estimate the following partially\n",
    "linear model\n",
    "\n",
    "$$\n",
    " Y_{j,t} = \\beta D_{j,(t-1)} + g(Z_{j,t}) + \\epsilon_{j,t}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016649,
     "end_time": "2021-02-13T17:30:13.315270",
     "exception": false,
     "start_time": "2021-02-13T17:30:13.298621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018756,
     "end_time": "2021-02-13T17:30:13.351290",
     "exception": false,
     "start_time": "2021-02-13T17:30:13.332534",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "$Y_{j,t}$ is log homicide rate in county $j$ at time $t$, $D_{j, t-1}$ is log  fraction of suicides committed with a firearm in county $j$ at time $t-1$, which we use as a proxy for gun ownership,  and  $Z_{j,t}$ is a set of demographic and economic characteristics of county $j$ at time $t$. The parameter $\\beta$ is the effect of gun ownership on the\n",
    "homicide rates, controlling for county-level demographic and economic characteristics. \n",
    "\n",
    "The sample covers 195 large United States counties between the years 1980 through 1999, giving us 3900 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv( r\"../data/gun_clean.csv\" )\n",
    "data1.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017216,
     "end_time": "2021-02-13T17:30:14.432656",
     "exception": false,
     "start_time": "2021-02-13T17:30:14.415440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017212,
     "end_time": "2021-02-13T17:30:14.467075",
     "exception": false,
     "start_time": "2021-02-13T17:30:14.449863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To account for heterogeneity across counties and time trends in  all variables, we remove from them county-specific and time-specific effects in the following preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-299-165111bd83a4>:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rdata[f'{var_name}'] = smf.ols( formula = form , data = data1 ).fit().resid\n"
     ]
    }
   ],
   "source": [
    "#################################  Find Variable Names from Dataset ########################\n",
    "\n",
    "def varlist( df = None, type_dataframe = [ 'numeric' , 'categorical' , 'string' ],  pattern = \"\", exclude = None ):\n",
    "    varrs = []\n",
    "    \n",
    "    if ('numeric' in type_dataframe):\n",
    "        varrs = varrs + df.columns[ df.apply( is_numeric_dtype , axis = 0 ).to_list() ].tolist()\n",
    "    \n",
    "    if ('categorical' in type_dataframe):\n",
    "        varrs = varrs + df.columns[ df.apply( is_categorical_dtype , axis = 0 ).to_list() ].tolist()\n",
    "    \n",
    "    if ('string' in type_dataframe):\n",
    "        varrs = varrs + df.columns[ df.apply( is_string_dtype , axis = 0 ).to_list() ].tolist()\n",
    "    \n",
    "    grepl_result = np.array( [ re.search( pattern , variable ) is not None for variable in df.columns.to_list() ] )\n",
    "    \n",
    "    if exclude is None:\n",
    "        result = list(compress( varrs, grepl_result ) )\n",
    "    \n",
    "    else:\n",
    "        varrs_excluded = np.array( [var in exclude for var in varrs ] )\n",
    "        and_filter = np.logical_and( ~varrs_excluded ,  grepl_result )\n",
    "        result = list(compress( varrs, and_filter ) )\n",
    "    \n",
    "    return result   \n",
    "\n",
    "################################# Create Variables ###############################\n",
    "\n",
    "\n",
    "# Dummy Variables for Year and County Fixed Effects\n",
    "r = re.compile(\"X_Jfips\")\n",
    "fixed = list( filter( r.match, data1.columns.to_list() ) )\n",
    "year = varlist(data1, pattern=\"X_Tyear\")\n",
    "\n",
    "census = []\n",
    "census_var = [\"^AGE\", \"^BN\", \"^BP\", \"^BZ\", \"^ED\", \"^EL\",\"^HI\", \"^HS\", \"^INC\", \"^LF\", \"^LN\", \"^PI\", \"^PO\", \"^PP\", \"^PV\", \"^SPR\", \"^VS\"]\n",
    "\n",
    "for variable in census_var:\n",
    "    r = re.compile( variable )\n",
    "    census = census + list( filter( r.match, data1.columns.to_list() ) )\n",
    "\n",
    "    \n",
    "################################ Variables ##################################\n",
    "# Treatment Variable\n",
    "d = \"logfssl\"\n",
    "\n",
    "# Outcome Variable\n",
    "y = \"logghomr\"\n",
    "\n",
    "# Other Control Variables\n",
    "X1 = [\"logrobr\", \"logburg\", \"burg_missing\", \"robrate_missing\"]\n",
    "X2 = [\"newblack\", \"newfhh\", \"newmove\", \"newdens\", \"newmal\"]\n",
    "\n",
    "#################################  Partial out Fixed Effects ########################\n",
    "\n",
    "rdata = data1[['CountyCode']]\n",
    "\n",
    "# Variables to be Partialled-out\n",
    "varlist2 = [y] + [d] + X1 + X2 + census\n",
    "\n",
    "# Partial out Variables in varlist from year and county fixed effect\n",
    "for var_name in varlist2:\n",
    "    form = var_name + \" ~ \"  + \" + \".join( year ) + \"+\" + \" + \".join( fixed )\n",
    "    rdata[f'{var_name}'] = smf.ols( formula = form , data = data1 ).fit().resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "rdata_read = pyreadr.read_r(\"../data/gun_clean.RData\")\n",
    "data = rdata_read[ 'data' ]\n",
    "n = data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We check that our results are equal to R results at 6 decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column logghomr are equal at 6 decimals.\n",
      "Column logfssl are equal at 6 decimals.\n",
      "Column logrobr are equal at 6 decimals.\n",
      "Column logburg are equal at 6 decimals.\n",
      "Column burg_missing are equal at 6 decimals.\n",
      "Column robrate_missing are equal at 6 decimals.\n",
      "Column newblack are equal at 6 decimals.\n",
      "Column newfhh are equal at 6 decimals.\n",
      "Column newmove are equal at 6 decimals.\n",
      "Column newdens are equal at 6 decimals.\n",
      "Column newmal are equal at 6 decimals.\n",
      "Column AGE010D are equal at 6 decimals.\n",
      "Column AGE050D are equal at 6 decimals.\n",
      "Column AGE110D are equal at 6 decimals.\n",
      "Column AGE170D are equal at 6 decimals.\n",
      "Column AGE180D are equal at 6 decimals.\n",
      "Column AGE270D are equal at 6 decimals.\n",
      "Column AGE310D are equal at 6 decimals.\n",
      "Column AGE320D are equal at 6 decimals.\n",
      "Column AGE350D are equal at 6 decimals.\n",
      "Column AGE380D are equal at 6 decimals.\n",
      "Column AGE410D are equal at 6 decimals.\n",
      "Column AGE470D are equal at 6 decimals.\n",
      "Column AGE570D are equal at 6 decimals.\n",
      "Column AGE640D are equal at 6 decimals.\n",
      "Column AGE670D are equal at 6 decimals.\n",
      "Column AGE760D are equal at 6 decimals.\n",
      "Column BNK010D are equal at 6 decimals.\n",
      "Column BNK050D are equal at 6 decimals.\n",
      "Column BPS030D are equal at 6 decimals.\n",
      "Column BPS130D are equal at 6 decimals.\n",
      "Column BPS230D are equal at 6 decimals.\n",
      "Column BPS020D are equal at 6 decimals.\n",
      "Column BPS120D are equal at 6 decimals.\n",
      "Column BPS220D are equal at 6 decimals.\n",
      "Column BPS820D are equal at 6 decimals.\n",
      "Column BZA010D are equal at 6 decimals.\n",
      "Column BZA110D are equal at 6 decimals.\n",
      "Column BZA210D are equal at 6 decimals.\n",
      "Column EDU100D are equal at 6 decimals.\n",
      "Column EDU200D are equal at 6 decimals.\n",
      "Column EDU600D are equal at 6 decimals.\n",
      "Column EDU610D are equal at 6 decimals.\n",
      "Column EDU620D are equal at 6 decimals.\n",
      "Column EDU630D are equal at 6 decimals.\n",
      "Column EDU635D are equal at 6 decimals.\n",
      "Column EDU640D are equal at 6 decimals.\n",
      "Column EDU650D are equal at 6 decimals.\n",
      "Column EDU680D are equal at 6 decimals.\n",
      "Column EDU685D are equal at 6 decimals.\n",
      "Column ELE010D are equal at 6 decimals.\n",
      "Column ELE020D are equal at 6 decimals.\n",
      "Column ELE025D are equal at 6 decimals.\n",
      "Column ELE030D are equal at 6 decimals.\n",
      "Column ELE035D are equal at 6 decimals.\n",
      "Column ELE060D are equal at 6 decimals.\n",
      "Column ELE065D are equal at 6 decimals.\n",
      "Column ELE210D are equal at 6 decimals.\n",
      "Column ELE220D are equal at 6 decimals.\n",
      "Column HIS010D are equal at 6 decimals.\n",
      "Column HIS020D are equal at 6 decimals.\n",
      "Column HIS030D are equal at 6 decimals.\n",
      "Column HIS040D are equal at 6 decimals.\n",
      "Column HIS110D are equal at 6 decimals.\n",
      "Column HIS120D are equal at 6 decimals.\n",
      "Column HIS130D are equal at 6 decimals.\n",
      "Column HIS140D are equal at 6 decimals.\n",
      "Column HIS200D are equal at 6 decimals.\n",
      "Column HIS300D are equal at 6 decimals.\n",
      "Column HIS500D are equal at 6 decimals.\n",
      "Column HIS700D are equal at 6 decimals.\n",
      "Column HSD010D are equal at 6 decimals.\n",
      "Column HSD020D are equal at 6 decimals.\n",
      "Column HSD030D are equal at 6 decimals.\n",
      "Column HSD110D are equal at 6 decimals.\n",
      "Column HSD120D are equal at 6 decimals.\n",
      "Column HSD130D are equal at 6 decimals.\n",
      "Column HSD140D are equal at 6 decimals.\n",
      "Column HSD150D are equal at 6 decimals.\n",
      "Column HSD170D are equal at 6 decimals.\n",
      "Column HSD200D are equal at 6 decimals.\n",
      "Column HSD210D are equal at 6 decimals.\n",
      "Column HSD230D are equal at 6 decimals.\n",
      "Column HSD300D are equal at 6 decimals.\n",
      "Column HSD310D are equal at 6 decimals.\n",
      "Column HSG030D are equal at 6 decimals.\n",
      "Column HSG195D are equal at 6 decimals.\n",
      "Column HSG200D are equal at 6 decimals.\n",
      "Column HSG220D are equal at 6 decimals.\n",
      "Column HSG440D are equal at 6 decimals.\n",
      "Column HSG445D are equal at 6 decimals.\n",
      "Column HSG460D are equal at 6 decimals.\n",
      "Column HSG680D are equal at 6 decimals.\n",
      "Column HSG700D are equal at 6 decimals.\n",
      "Column HSD410D are equal at 6 decimals.\n",
      "Column HSD500D are equal at 6 decimals.\n",
      "Column HSD510D are equal at 6 decimals.\n",
      "Column HSD520D are equal at 6 decimals.\n",
      "Column HSD530D are equal at 6 decimals.\n",
      "Column HSD540D are equal at 6 decimals.\n",
      "Column HSD550D are equal at 6 decimals.\n",
      "Column HSD560D are equal at 6 decimals.\n",
      "Column HSD570D are equal at 6 decimals.\n",
      "Column HSD580D are equal at 6 decimals.\n",
      "Column HSD590D are equal at 6 decimals.\n",
      "Column HSD610D are equal at 6 decimals.\n",
      "Column HSD620D are equal at 6 decimals.\n",
      "Column HSD710D are equal at 6 decimals.\n",
      "Column HSD720D are equal at 6 decimals.\n",
      "Column HSD730D are equal at 6 decimals.\n",
      "Column HSD740D are equal at 6 decimals.\n",
      "Column HSD750D are equal at 6 decimals.\n",
      "Column HSD760D are equal at 6 decimals.\n",
      "Column HSD770D are equal at 6 decimals.\n",
      "Column HSD780D are equal at 6 decimals.\n",
      "Column HSG040D are equal at 6 decimals.\n",
      "Column HSG045D are equal at 6 decimals.\n",
      "Column HSG050D are equal at 6 decimals.\n",
      "Column HSG182D are equal at 6 decimals.\n",
      "Column HSG210D are equal at 6 decimals.\n",
      "Column HSG230D are equal at 6 decimals.\n",
      "Column HSG240D are equal at 6 decimals.\n",
      "Column HSG250D are equal at 6 decimals.\n",
      "Column HSG310D are equal at 6 decimals.\n",
      "Column HSG315D are equal at 6 decimals.\n",
      "Column HSG320D are equal at 6 decimals.\n",
      "Column HSG325D are equal at 6 decimals.\n",
      "Column HSG335D are equal at 6 decimals.\n",
      "Column HSG350D are equal at 6 decimals.\n",
      "Column HSG370D are equal at 6 decimals.\n",
      "Column HSG375D are equal at 6 decimals.\n",
      "Column HSG380D are equal at 6 decimals.\n",
      "Column HSG450D are equal at 6 decimals.\n",
      "Column HSG490D are equal at 6 decimals.\n",
      "Column HSG500D are equal at 6 decimals.\n",
      "Column HSG510D are equal at 6 decimals.\n",
      "Column HSG520D are equal at 6 decimals.\n",
      "Column HSG530D are equal at 6 decimals.\n",
      "Column HSG540D are equal at 6 decimals.\n",
      "Column HSG550D are equal at 6 decimals.\n",
      "Column HSG560D are equal at 6 decimals.\n",
      "Column HSG570D are equal at 6 decimals.\n",
      "Column HSG650D are equal at 6 decimals.\n",
      "Column HSG690D are equal at 6 decimals.\n",
      "Column HSG710D are equal at 6 decimals.\n",
      "Column HSG730D are equal at 6 decimals.\n",
      "Column INC110D are equal at 6 decimals.\n",
      "Column INC650D are equal at 6 decimals.\n",
      "Column INC670D are equal at 6 decimals.\n",
      "Column INC680D are equal at 6 decimals.\n",
      "Column INC690D are equal at 6 decimals.\n",
      "Column INC700D are equal at 6 decimals.\n",
      "Column INC710D are equal at 6 decimals.\n",
      "Column INC720D are equal at 6 decimals.\n",
      "Column INC730D are equal at 6 decimals.\n",
      "Column INC760D are equal at 6 decimals.\n",
      "Column INC790D are equal at 6 decimals.\n",
      "Column LFE020D are equal at 6 decimals.\n",
      "Column LFE023D are equal at 6 decimals.\n",
      "Column LFE030D are equal at 6 decimals.\n",
      "Column LFE080D are equal at 6 decimals.\n",
      "Column LFE090D are equal at 6 decimals.\n",
      "Column LFE210D are equal at 6 decimals.\n",
      "Column LFE220D are equal at 6 decimals.\n",
      "Column LND110D are equal at 6 decimals.\n",
      "Column PIN020D are equal at 6 decimals.\n",
      "Column POP110D are equal at 6 decimals.\n",
      "Column POP210D are equal at 6 decimals.\n",
      "Column POP240D are equal at 6 decimals.\n",
      "Column POP440D are equal at 6 decimals.\n",
      "Column POP450D are equal at 6 decimals.\n",
      "Column POP470D are equal at 6 decimals.\n",
      "Column POP480D are equal at 6 decimals.\n",
      "Column POP540D are equal at 6 decimals.\n",
      "Column POP550D are equal at 6 decimals.\n",
      "Column POP570D are equal at 6 decimals.\n",
      "Column POP580D are equal at 6 decimals.\n",
      "Column POP700D are equal at 6 decimals.\n",
      "Column POP710D are equal at 6 decimals.\n",
      "Column POP720D are equal at 6 decimals.\n",
      "Column POP740D are equal at 6 decimals.\n",
      "Column PPQ010D are equal at 6 decimals.\n",
      "Column PPQ100D are equal at 6 decimals.\n",
      "Column PPQ110D are equal at 6 decimals.\n",
      "Column PPQ120D are equal at 6 decimals.\n",
      "Column PVY020D are equal at 6 decimals.\n",
      "Column PVY120D are equal at 6 decimals.\n",
      "Column PVY210D are equal at 6 decimals.\n",
      "Column PVY310D are equal at 6 decimals.\n",
      "Column PVY420D are equal at 6 decimals.\n",
      "Column PVY520D are equal at 6 decimals.\n",
      "Column SPR030D are equal at 6 decimals.\n",
      "Column SPR130D are equal at 6 decimals.\n",
      "Column SPR230D are equal at 6 decimals.\n",
      "Column SPR330D are equal at 6 decimals.\n",
      "Column SPR440D are equal at 6 decimals.\n",
      "Column VST020D are equal at 6 decimals.\n",
      "Column CountyCode are equal at 6 decimals.\n"
     ]
    }
   ],
   "source": [
    "column_names = data.columns.to_list()\n",
    "\n",
    "for col in column_names:\n",
    "    result = (data[f'{col}'].round(6) == rdata[f'{col}'].round(6)).sum()\n",
    "    \n",
    "    if result == 3900:\n",
    "        print(f'Column {col} are equal at 6 decimals.')\n",
    "    else:\n",
    "        print(f'\\n\\nColumn {col} are not equal at 6 decimals.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can construct the treatment variable, the outcome variable and the matrix $Z$ that includes the control variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 195)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treatment Variable\n",
    "D = rdata[ f'{d}']\n",
    "\n",
    "# Outcome Variable\n",
    "Y = rdata[ f'{y}']\n",
    "\n",
    "# Construct matrix Z\n",
    "Z = rdata[ X1 + X2 + census ]\n",
    "\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have in total 195 control variables. The control variables $Z_{j,t}$ are from the U.S. Census Bureau and  contain demographic and economic characteristics of the counties such as  the age distribution, the income distribution, crime rates, federal spending, home ownership rates, house prices, educational attainment, voting paterns, employment statistics, and migration rates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "clu = rdata[['CountyCode']]\n",
    "data = pd.concat([Y, D, Z, clu], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv( r\"../data/gun_clean2.csv\" , index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01855,
     "end_time": "2021-02-13T17:30:40.260049",
     "exception": false,
     "start_time": "2021-02-13T17:30:40.241499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The effect of gun ownership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018478,
     "end_time": "2021-02-13T17:30:40.297035",
     "exception": false,
     "start_time": "2021-02-13T17:30:40.278557",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018386,
     "end_time": "2021-02-13T17:30:40.333613",
     "exception": false,
     "start_time": "2021-02-13T17:30:40.315227",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After preprocessing the data, we first look at simple regression of $Y_{j,t}$ on $D_{j,t-1}$ without controls as a baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this line to avoid all the lines of code above\n",
    "# data = pd.read_csv( r\"../data/gun_clean2.csv\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025    0.154480\n",
      "0.975]    0.410129\n",
      "Name: logfssl, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Coef.       0.282304\n",
       "Std.Err.    0.064811\n",
       "t           4.355825\n",
       "P>|t|       0.000021\n",
       "[0.025      0.154480\n",
       "0.975]      0.410129\n",
       "Name: logfssl, dtype: float64"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLS clustering at the County level\n",
    "model = \"logghomr ~ logfssl\"\n",
    "baseline_ols = smf.ols(model , data=data).fit().get_robustcov_results(cov_type = \"cluster\", groups= data['CountyCode'])\n",
    "baseline_ols_table = baseline_ols.summary2().tables[1]\n",
    "print( baseline_ols_table.iloc[ 1 , 4:] )\n",
    "baseline_ols_table.iloc[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019514,
     "end_time": "2021-02-13T17:30:40.528479",
     "exception": false,
     "start_time": "2021-02-13T17:30:40.508965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The point estimate is $0.282$ with the confidence interval ranging from 0.155 to 0.41. This\n",
    "suggests that increases in gun ownership rates are related to gun homicide rates - if gun ownership increases by 1% relative\n",
    "to a trend then the predicted gun homicide rate goes up by 0.28%, without controlling for counties' characteristics.\n",
    "\n",
    "Since our goal is to estimate the effect of gun ownership after controlling for a rich set county characteristics we next include the controls. First, we estimate the model by ols and then by an array of the modern regression methods using the double machine learning approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logghomr ~ logfssl + logrobr + logburg + burg_missing + robrate_missing + newblack + newfhh + newmove + newdens + newmal + AGE010D + AGE050D + AGE110D + AGE170D + AGE180D + AGE270D + AGE310D + AGE320D + AGE350D + AGE380D + AGE410D + AGE470D + AGE570D + AGE640D + AGE670D + AGE760D + BNK010D + BNK050D + BPS030D + BPS130D + BPS230D + BPS020D + BPS120D + BPS220D + BPS820D + BZA010D + BZA110D + BZA210D + EDU100D + EDU200D + EDU600D + EDU610D + EDU620D + EDU630D + EDU635D + EDU640D + EDU650D + EDU680D + EDU685D + ELE010D + ELE020D + ELE025D + ELE030D + ELE035D + ELE060D + ELE065D + ELE210D + ELE220D + HIS010D + HIS020D + HIS030D + HIS040D + HIS110D + HIS120D + HIS130D + HIS140D + HIS200D + HIS300D + HIS500D + HIS700D + HSD010D + HSD020D + HSD030D + HSD110D + HSD120D + HSD130D + HSD140D + HSD150D + HSD170D + HSD200D + HSD210D + HSD230D + HSD300D + HSD310D + HSG030D + HSG195D + HSG200D + HSG220D + HSG440D + HSG445D + HSG460D + HSG680D + HSG700D + HSD410D + HSD500D + HSD510D + HSD520D + HSD530D + HSD540D + HSD550D + HSD560D + HSD570D + HSD580D + HSD590D + HSD610D + HSD620D + HSD710D + HSD720D + HSD730D + HSD740D + HSD750D + HSD760D + HSD770D + HSD780D + HSG040D + HSG045D + HSG050D + HSG182D + HSG210D + HSG230D + HSG240D + HSG250D + HSG310D + HSG315D + HSG320D + HSG325D + HSG335D + HSG350D + HSG370D + HSG375D + HSG380D + HSG450D + HSG490D + HSG500D + HSG510D + HSG520D + HSG530D + HSG540D + HSG550D + HSG560D + HSG570D + HSG650D + HSG690D + HSG710D + HSG730D + INC110D + INC650D + INC670D + INC680D + INC690D + INC700D + INC710D + INC720D + INC730D + INC760D + INC790D + LFE020D + LFE023D + LFE030D + LFE080D + LFE090D + LFE210D + LFE220D + LND110D + PIN020D + POP110D + POP210D + POP240D + POP440D + POP450D + POP470D + POP480D + POP540D + POP550D + POP570D + POP580D + POP700D + POP710D + POP720D + POP740D + PPQ010D + PPQ100D + PPQ110D + PPQ120D + PVY020D + PVY120D + PVY210D + PVY310D + PVY420D + PVY520D + SPR030D + SPR130D + SPR230D + SPR330D + SPR440D + VST020D'"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_formula = \"logghomr\" + ' ~ ' + 'logfssl + ' + ' + '.join( Z.columns.to_list() )\n",
    "control_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_ols = smf.ols( control_formula , data=data).fit().get_robustcov_results(cov_type = \"cluster\", groups= data['CountyCode'])\n",
    "control_ols_table = control_ols.summary2().tables[1]\n",
    "print( control_ols_table.iloc[ 1 , 4:] )\n",
    "control_ols_table.iloc[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039309,
     "end_time": "2021-02-13T17:30:40.858783",
     "exception": false,
     "start_time": "2021-02-13T17:30:40.819474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After controlling for a rich set of characteristics, the point estimate of gun ownership reduces to $0.19$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022083,
     "end_time": "2021-02-13T17:30:40.902070",
     "exception": false,
     "start_time": "2021-02-13T17:30:40.879987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DML algorithm\n",
    "\n",
    "Here we perform inference of the predictive coefficient $\\beta$ in our partially linear statistical model, \n",
    "\n",
    "$$\n",
    "Y = D\\beta + g(Z) + \\epsilon, \\quad E (\\epsilon | D, Z) = 0,\n",
    "$$\n",
    "\n",
    "using the **double machine learning** approach. \n",
    "\n",
    "For $\\tilde Y = Y- E(Y|Z)$ and $\\tilde D= D- E(D|Z)$, we can write\n",
    "$$\n",
    "\\tilde Y = \\alpha \\tilde D + \\epsilon, \\quad E (\\epsilon |\\tilde D) =0.\n",
    "$$\n",
    "\n",
    "Using cross-fitting, we employ modern regression methods\n",
    "to build estimators $\\hat \\ell(Z)$ and $\\hat m(Z)$ of $\\ell(Z):=E(Y|Z)$ and $m(Z):=E(D|Z)$ to obtain the estimates of the residualized quantities:\n",
    "\n",
    "$$\n",
    "\\tilde Y_i = Y_i  - \\hat \\ell (Z_i),   \\quad \\tilde D_i = D_i - \\hat m(Z_i), \\quad \\text{ for each } i = 1,\\dots,n.\n",
    "$$\n",
    "\n",
    "Finally, using ordinary least squares of $\\tilde Y_i$ on $\\tilde D_i$, we obtain the \n",
    "estimate of $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021101,
     "end_time": "2021-02-13T17:30:40.944373",
     "exception": false,
     "start_time": "2021-02-13T17:30:40.923272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following algorithm comsumes $Y, D, Z$, and a machine learning method for learning the residuals $\\tilde Y$ and $\\tilde D$, where the residuals are obtained by cross-validation (cross-fitting). Then, it prints the estimated coefficient $\\beta$ and the corresponding standard error from the final OLS regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as matrix\n",
    "y = Y.to_numpy().reshape( len(Y) , 1 )\n",
    "d = D.to_numpy().reshape( len(Y) , 1 )\n",
    "z = Z.to_numpy()\n",
    "clu = clu.to_numpy().reshape( len(Y) , 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DML2_for_PLM(z, d, y, dreg, yreg, nfold, clu):\n",
    "    \n",
    "    # Num ob observations\n",
    "    nobs = z.shape[0]\n",
    "    \n",
    "    # Define folds indices \n",
    "    list_1 = [*range(0, nfold, 1)]*nobs\n",
    "    sample = np.random.choice(nobs,nobs, replace=False).tolist()\n",
    "    foldid = [list_1[index] for index in sample]\n",
    "\n",
    "    # Create split function(similar to R)\n",
    "    def split(x, f):\n",
    "        count = max(f) + 1\n",
    "        return tuple( list(itertools.compress(x, (el == i for el in f))) for i in range(count) ) \n",
    "\n",
    "    # Split observation indices into folds \n",
    "    list_2 = [*range(0, nobs, 1)]\n",
    "    I = split(list_2, foldid)\n",
    "    \n",
    "    # Create array to save errors \n",
    "    dtil = np.zeros( len(z) ).reshape( len(z) , 1 )\n",
    "    ytil = np.zeros( len(z) ).reshape( len(z) , 1 )\n",
    "    \n",
    "    # loop to save results\n",
    "    for b in range(0,len(I)):\n",
    "    \n",
    "        # Split data - index to keep are in mask as booleans\n",
    "        include_idx = set(I[b])  #Here should go I[b] Set is more efficient, but doesn't reorder your elements if that is desireable\n",
    "        mask = np.array([(i in include_idx) for i in range(len(z))])\n",
    "\n",
    "        # Lasso regression, excluding folds selected \n",
    "        dfit = dreg(z[~mask,], d[~mask,])\n",
    "        yfit = yreg(z[~mask,], y[~mask,])\n",
    "\n",
    "        # predict estimates using the \n",
    "        dhat = dfit.predict( z[mask,] )\n",
    "        yhat = yfit.predict( z[mask,] )\n",
    "\n",
    "        # save errors  \n",
    "        dtil[mask] =  d[mask,] - dhat.reshape( len(I[b]) , 1 )\n",
    "        ytil[mask] = y[mask,] - yhat.reshape( len(I[b]) , 1 )\n",
    "        print(b, \" \")\n",
    "    \n",
    "    # Create dataframe \n",
    "    data_2 = pd.DataFrame(np.concatenate( ( ytil, dtil,clu ), axis = 1), columns = ['ytil','dtil','CountyCode'])\n",
    "   \n",
    "    # OLS clustering at the County level\n",
    "    model = \"ytil ~ dtil\"\n",
    "    baseline_ols = smf.ols(model , data=data).fit().get_robustcov_results(cov_type = \"cluster\", groups= data_2['CountyCode'])\n",
    "    coef_est = baseline_ols.summary2().tables[1]['Coef.']['dtil']\n",
    "    se = baseline_ols.summary2().tables[1]['Std.Err.']['dtil']\n",
    "    \n",
    "    Final_result = { 'coef_est' : coef_est , 'se' : se , 'dtil' : dtil , 'ytil' : ytil }\n",
    "\n",
    "    print(\"Coefficient is {}, SE is equal to {}\".format(coef_est, se))\n",
    "    \n",
    "    return Final_result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.674735395967629, tolerance: 0.002864909854321656\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 140.81523453499932, tolerance: 0.03618879801918865\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.682128784205268, tolerance: 0.0025091298640074386\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  \n",
      "Coefficient is 0.22828848301587235, SE is equal to 0.07867826261327843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 130.44928205824675, tolerance: 0.03296600864704124\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "def dreg(z,d):\n",
    "    alpha=0.00000001\n",
    "    result = linear_model.Lasso(alpha = alpha).fit(z, d)\n",
    "    return result\n",
    "\n",
    "def yreg(z,y):\n",
    "    alpha=0.00000001\n",
    "    result = linear_model.Lasso(alpha = alpha).fit(z, y)\n",
    "    return result\n",
    "\n",
    "DML2_lasso = DML2_for_PLM(z, d, y, dreg, yreg, 10, clu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use SelectFromModel to select variables which do not have a zero coefficient. It is done because we want to reduce dimensionality as rlasso( post = T ) does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lasso_post:\n",
    "    \n",
    "    def __init__(self, alpha ):\n",
    "        self.alpha = alpha\n",
    "\n",
    "        \n",
    "    def fit( self, X, Y ):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        lasso = linear_model.Lasso( alpha = alpha ).fit( X , Y )\n",
    "        model = SelectFromModel( lasso , prefit = True )\n",
    "        X_new = model.transform( X )\n",
    "        # Gettin indices from columns which has variance for regression\n",
    "        index_X = model.get_support()\n",
    "        \n",
    "        self.index = index_X\n",
    "        new_x = X[ : ,  index_X ]\n",
    "        \n",
    "        lasso2 = linear_model.Lasso( alpha = alpha ).fit( new_x , Y )\n",
    "        self.model = lasso2\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict( self , X ):\n",
    "        \n",
    "        dropped_X = X[ : , self.index ]\n",
    "        \n",
    "        predictions = self.model.predict( dropped_X )\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below code to verify whether Lasso_post functions as it is expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # setting alpha \n",
    "# alpha = 0.00000001\n",
    "\n",
    "# # fit original model\n",
    "# lasso = linear_model.Lasso( alpha = alpha ).fit( z , d )\n",
    "# # select non zero coefficient variables\n",
    "# model = SelectFromModel( lasso , prefit = True )\n",
    "# # Dropping zero coefficient variables\n",
    "# z_new = model.transform( z )\n",
    "# # Getting the index of non zero coefficient variables\n",
    "# index_X = model.get_support()\n",
    "# # fitting a new model with the selected variables\n",
    "# lasso2 = linear_model.Lasso( alpha = alpha ).fit( z[ : ,  index_X ] , d )\n",
    "# # predictions with selected variables\n",
    "# resultado = lasso2.predict( z[ : ,  index_X ] )\n",
    "\n",
    "# # Making rlasso( post = T ) with Lasso_post \n",
    "# model1 = Lasso_post( alpha = alpha )\n",
    "# mdfit = model1.fit( z, d )\n",
    "# resultado2 = mdfit.predict( z )\n",
    "\n",
    "# np.sum(resultado == resultado2)\n",
    "# # the number of values which are equal are equal to the number of observations.\n",
    "# # We conclude that our new class Lasso_post runs what we desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dreg(z,d):\n",
    "    alpha=0.00000001\n",
    "    result = Lasso_post( alpha = alpha ).fit( z , d )\n",
    "    return result\n",
    "\n",
    "def yreg( z , y ):\n",
    "    alpha = 0.00000001\n",
    "    result = Lasso_post( alpha = alpha ).fit( z , y )\n",
    "    return result\n",
    "\n",
    "DML2_lasso_post = DML2_for_PLM(z, d, y, dreg, yreg, 10, clu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv.glmnet curiosities\n",
    "1. According to [link1](https://stackoverflow.com/questions/24098212/what-does-the-option-normalize-true-in-lasso-sklearn-do) and [link2](https://statisticaloddsandends.wordpress.com/2018/11/15/a-deep-dive-into-glmnet-standardize/), It standardize **X** variables before estimation. In sklearn we have an option named **normalize**. It normalizes **X** by subtracting the mean and dividing by the l2-norm. Based on [link3](https://stackoverflow.com/questions/59846325/confusion-about-standardize-option-of-glmnet-package-in-r), **cv.glmnet (standardize = TRUE)** and **sklearn (normlize = True)** are not the same. We decided to use **StandardScaler** that meets suggestions made in **link3**. We proved this in the commented code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([ 6, 7, 8, 12, 15]).reshape( a.size, 1)\n",
    "\n",
    "# scaler_a = StandardScaler()\n",
    "# scaler_a.fit( a )\n",
    "# print( scaler_a.transform( a ) )\n",
    "\n",
    "# def std_1( x ):\n",
    "#     val = ( (1 / x.size )*np.sum( ( x - np.mean( x ) ) ** 2 ) ) ** 0.5\n",
    "#     return val\n",
    "\n",
    "# ( a - np.mean(a) ) / std_1( a )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "class standard_skl_model:\n",
    "    \n",
    "    def __init__(self, model ):\n",
    "        self.model = model\n",
    "       \n",
    "    def fit( self, X, Y ):\n",
    "        \n",
    "        # Standarization of X and Y\n",
    "        self.scaler_X = StandardScaler()\n",
    "        self.scaler_X.fit( X )\n",
    "        std_X = self.scaler_X.transform( X )\n",
    "                \n",
    "        self.model.fit( std_X , Y )\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def predict( self , X ):\n",
    "        \n",
    "        self.scaler_X = StandardScaler()\n",
    "        self.scaler_X.fit( X )\n",
    "        std_X = self.scaler_X.transform( X )\n",
    "        \n",
    "        prediction = self.model.predict( std_X )\n",
    "        \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below code to verify whether standard_skl_model functions as it is expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Regular Operation using StandardScaler\n",
    "# # Standarization of z\n",
    "# scaler_z = StandardScaler()\n",
    "# scaler_z.fit( z )\n",
    "# std_z = scaler_z.transform( z )\n",
    "# # Lasso CV prediction and getting normal \n",
    "# model1 = LassoCV(cv = 10 , random_state = 0 ).fit( std_z, std_d )\n",
    "# predict1 = model1.predict( std_z )\n",
    "\n",
    "# # Class standard_skl_model\n",
    "# model2 = standard_skl_model( LassoCV(cv = 10 , random_state = 0 ) ).fit( z, d)\n",
    "# predict2 = model2.predict( z )\n",
    "\n",
    "# # Checking two results\n",
    "# np.sum(real_predict1 == real_predict2)\n",
    "# # the number of values which are equal are equal to the number of observations.\n",
    "# # We conclude that our new class standard_skl_model runs what we desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DML with cross-validated Lasso:\n",
    "def dreg(z,d):\n",
    "    result = standard_skl_model( LassoCV(cv = 10 , random_state = 0 ) ).fit( z, d )\n",
    "    return result\n",
    "\n",
    "def yreg(z,y):\n",
    "    result = standard_skl_model( LassoCV(cv = 10 , random_state = 0  ) ).fit( z, y )\n",
    "    return result\n",
    "\n",
    "DML2_lasso_cv = DML2_for_PLM(z, d, y, dreg, yreg, 10 , clu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DML with cross-validated Lasso:\n",
    "def dreg(z,d):\n",
    "    result = standard_skl_model( ElasticNetCV( cv = 10 , random_state = 0 , l1_ratio = 0.5, max_iter = 100000 ) ).fit( z, d )\n",
    "    return result\n",
    "\n",
    "def yreg(z,y):\n",
    "    result = standard_skl_model( ElasticNetCV( cv = 10 , random_state = 0 , l1_ratio = 0.5, max_iter = 100000 ) ).fit( z, y )\n",
    "    return result\n",
    "\n",
    "DML2_elnet = DML2_for_PLM(z, d, y, dreg, yreg, 10 , clu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DML with cross-validated Lasso:\n",
    "def dreg(z,d):\n",
    "    result = standard_skl_model( ElasticNetCV( cv = 10 ,  random_state = 0 , l1_ratio = 0.0001 ) ).fit( z, d )\n",
    "    return result\n",
    "\n",
    "def yreg(z,y):\n",
    "    result = standard_skl_model( ElasticNetCV( cv = 10 , random_state = 0 , l1_ratio = 0.0001 ) ).fit( z, y )\n",
    "    return result\n",
    "\n",
    "DML2_ridge = DML2_for_PLM(z, d, y, dreg, yreg, 10, clu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we also compute DML with OLS used as the ML method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n",
      "1  \n",
      "Coefficient is 0.1738154996405108, SE is equal to 0.051287432641185\n"
     ]
    }
   ],
   "source": [
    "#DML with cross-validated Lasso:\n",
    "def dreg(z,d):\n",
    "    result = LinearRegression().fit( z, d )\n",
    "    return result\n",
    "\n",
    "def yreg(z,y):\n",
    "    result = LinearRegression().fit( z, y )\n",
    "    return result\n",
    "\n",
    "DML2_ols = DML2_for_PLM(z, d, y, dreg, yreg, 10, clu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024512,
     "end_time": "2021-02-13T17:35:14.215612",
     "exception": false,
     "start_time": "2021-02-13T17:35:14.191100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we also apply Random Forest for comparison purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025256,
     "end_time": "2021-02-13T17:35:14.266042",
     "exception": false,
     "start_time": "2021-02-13T17:35:14.240786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-324-e21f895212cc>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  result = RandomForestRegressor( random_state = 0 , n_estimators = 500 , max_features = 65 , n_jobs = 4 , min_samples_leaf = 5 ).fit( z, d )\n",
      "<ipython-input-324-e21f895212cc>:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  result = RandomForestRegressor( random_state = 0 , n_estimators = 500 , max_features = 65 , n_jobs = 4 , min_samples_leaf = 5 ).fit( z, y )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-324-e21f895212cc>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  result = RandomForestRegressor( random_state = 0 , n_estimators = 500 , max_features = 65 , n_jobs = 4 , min_samples_leaf = 5 ).fit( z, d )\n",
      "<ipython-input-324-e21f895212cc>:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  result = RandomForestRegressor( random_state = 0 , n_estimators = 500 , max_features = 65 , n_jobs = 4 , min_samples_leaf = 5 ).fit( z, y )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  \n",
      "Coefficient is 0.12647896945883857, SE is equal to 0.05663338110770135\n"
     ]
    }
   ],
   "source": [
    "#DML with cross-validated Lasso:\n",
    "def dreg(z,d):\n",
    "    result = RandomForestRegressor( random_state = 0 , n_estimators = 500 , max_features = 65 , n_jobs = 4 , min_samples_leaf = 5 ).fit( z, d )\n",
    "    return result\n",
    "\n",
    "def yreg(z,y):\n",
    "    result = RandomForestRegressor( random_state = 0 , n_estimators = 500 , max_features = 65 , n_jobs = 4 , min_samples_leaf = 5 ).fit( z, y )\n",
    "    return result\n",
    "\n",
    "DML2_RF = DML2_for_PLM(z, d, y, dreg, yreg, 10, clu)   # set to 2 due to computation time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024871,
     "end_time": "2021-02-13T17:40:48.605021",
     "exception": false,
     "start_time": "2021-02-13T17:40:48.580150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We conclude that the gun ownership rates are related to gun homicide rates - if gun ownership increases by 1% relative\n",
    "to a trend then the predicted gun homicide rate goes up by about 0.20% controlling for counties' characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027238,
     "end_time": "2021-02-13T17:40:48.657096",
     "exception": false,
     "start_time": "2021-02-13T17:40:48.629858",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, let's see which method is actually better. We compute RMSE for predicting D and Y, and see which\n",
    "of the methods works better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DML2_ols</th>\n",
       "      <th>DML2_lasso</th>\n",
       "      <th>DML2_lasso_post</th>\n",
       "      <th>DML2_lasso_cv</th>\n",
       "      <th>DML2_ridge</th>\n",
       "      <th>DML2_elnet</th>\n",
       "      <th>DML2_RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSEY</th>\n",
       "      <td>0.002580</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>2.277381e-19</td>\n",
       "      <td>7.401487e-19</td>\n",
       "      <td>2.846726e-19</td>\n",
       "      <td>0.000476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSED</th>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>6.405133e-19</td>\n",
       "      <td>3.060230e-19</td>\n",
       "      <td>2.419717e-19</td>\n",
       "      <td>0.000320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DML2_ols  DML2_lasso  DML2_lasso_post  DML2_lasso_cv    DML2_ridge  \\\n",
       "RMSEY  0.002580    0.002680         0.000099   2.277381e-19  7.401487e-19   \n",
       "RMSED  0.001416    0.000652         0.000959   6.405133e-19  3.060230e-19   \n",
       "\n",
       "         DML2_elnet   DML2_RF  \n",
       "RMSEY  2.846726e-19  0.000476  \n",
       "RMSED  2.419717e-19  0.000320  "
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods = [DML2_ols, DML2_lasso, DML2_lasso_post , DML2_lasso_cv, DML2_ridge, DML2_elnet, DML2_RF]\n",
    "mods_name = [\"DML2_ols\", \"DML2_lasso\", \"DML2_lasso_post\" , \"DML2_lasso_cv\", 'DML2_ridge', 'DML2_elnet', 'DML2_RF']\n",
    "\n",
    "def mdl( model , model_name ):\n",
    "    \n",
    "    RMSEY = np.sqrt( np.mean( model[ 'ytil' ] ) ** 2 ) # I have some doubts about these equations...we have to recheck\n",
    "    RMSED = np.sqrt( np.mean( model[ 'dtil' ] ) ** 2 ) # I have some doubts about these equations...we have to recheck\n",
    "    \n",
    "    result = pd.DataFrame( { model_name : [ RMSEY , RMSED ]} , index = [ 'RMSEY' , 'RMSED' ])\n",
    "    return result\n",
    "\n",
    "RES = [ mdl( model , name ) for model, name in zip( mods , mods_name ) ]\n",
    "    \n",
    "\n",
    "pr_Res = pd.concat( RES, axis = 1)\n",
    "\n",
    "pr_Res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This verfies that the function DML2_for_PLM has no errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(DML2_lasso_post[ 'ytil' ] == 0)[0].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the best method for predicting D is Lasso, and the best method for predicting Y is CV Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DML with cross-validated Lasso:\n",
    "def dreg(z,d):\n",
    "    result = standard_skl_model( LassoCV(cv = 10 , random_state = 0 , alphas = [0]) ).fit( z, d )\n",
    "    return result\n",
    "\n",
    "\n",
    "def yreg(z,y):\n",
    "    result = standard_skl_model( ElasticNetCV( cv = 10 ,  random_state = 0 , l1_ratio = 0.0001 ) ).fit( z, y )\n",
    "    return result\n",
    "\n",
    "DML2_best = DML2_for_PLM(z, d, y , dreg, yreg, 10, clu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = np.zeros( ( 9 , 2 ))\n",
    "table[ 0 , 0] = baseline_ols_table.iloc[ 1 , 0 ]\n",
    "table[ 1 , 0] = control_ols_table.iloc[ 1 , 0 ]\n",
    "table[ 2 , 0] = DML2_lasso['coef_est']\n",
    "table[ 3 , 0] = DML2_lasso_post['coef_est']\n",
    "table[ 4 , 0] = DML2_lasso_cv['coef_est']\n",
    "table[ 5 , 0] = DML2_ridge['coef_est']\n",
    "table[ 6 , 0] = DML2_elnet['coef_est']\n",
    "table[ 7 , 0] = DML2_RF['coef_est']\n",
    "table[ 8 , 0] = DML2_best['coef_est']\n",
    "table[ 0 , 1] = baseline_ols_table.iloc[ 1 , 1 ]\n",
    "table[ 1 , 1] = control_ols_table.iloc[ 1 , 1 ]\n",
    "table[ 2 , 1] = DML2_lasso['se']\n",
    "table[ 3 , 1] = DML2_lasso_post['se']\n",
    "table[ 4 , 1] = DML2_lasso_cv['se']\n",
    "table[ 5 , 1] = DML2_ridge['se']\n",
    "table[ 6 , 1] = DML2_elnet['se']\n",
    "table[ 7 , 1] = DML2_RF['se']\n",
    "table[ 8 , 1] = DML2_best['se']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Standard Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline OLS</th>\n",
       "      <td>0.282</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Least Squares with controls</th>\n",
       "      <td>0.192</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.228</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post-Lasso</th>\n",
       "      <td>0.212</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV Lasso</th>\n",
       "      <td>0.231</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV Elnet</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV Ridge</th>\n",
       "      <td>0.207</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.126</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best</th>\n",
       "      <td>0.179</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Estimate  Standard Error\n",
       "Baseline OLS                    0.282           0.065\n",
       "Least Squares with controls     0.192           0.053\n",
       "Lasso                           0.228           0.079\n",
       "Post-Lasso                      0.212           0.054\n",
       "CV Lasso                        0.231           0.057\n",
       "CV Elnet                        0.200           0.056\n",
       "CV Ridge                        0.207           0.056\n",
       "Random Forest                   0.126           0.057\n",
       "Best                            0.179           0.052"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame( table , index = [ \"Baseline OLS\", \"Least Squares with controls\", \"Lasso\", \\\n",
    "             \"Post-Lasso\", \"CV Lasso\",\"CV Elnet\", \"CV Ridge\", \"Random Forest\", \"Best\" ] , \\\n",
    "            columns = [\"Estimate\",\"Standard Error\"] )\n",
    "table.round( 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrr}\\n\\\\toprule\\n{} &  Estimate &  Standard Error \\\\\\\\\\n\\\\midrule\\nBaseline OLS                &  0.282304 &        0.064811 \\\\\\\\\\nLeast Squares with controls &  0.191998 &        0.052921 \\\\\\\\\\nLasso                       &  0.228288 &        0.078678 \\\\\\\\\\nPost-Lasso                  &  0.212147 &        0.053999 \\\\\\\\\\nCV Lasso                    &  0.230827 &        0.056527 \\\\\\\\\\nCV Elnet                    &  0.200062 &        0.055897 \\\\\\\\\\nCV Ridge                    &  0.207452 &        0.056077 \\\\\\\\\\nRandom Forest               &  0.126479 &        0.056633 \\\\\\\\\\nBest                        &  0.178552 &        0.051706 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.to_latex()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
